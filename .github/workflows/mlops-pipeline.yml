name: MLOps Pipeline with DVC and Google Drive

on:
  push:
    branches: [ main ]
    paths:
      - 'AI_Service/app/data/intents_complete.json.dvc'
      - 'AI_Service/app/data/tasks_dataset.csv.dvc'
      - 'AI_Service/app/models/*.dvc'
      - 'AI_Service/app/chatbot/data/*.dvc'
      - 'AI_Service/app/**.py'
      - 'AI_Service/tests/**.py'
  pull_request:
    branches: [ main ]
    paths:
      - 'AI_Service/app/data/intents_complete.json.dvc'
      - 'AI_Service/app/data/tasks_dataset.csv.dvc'
      - 'AI_Service/app/models/*.dvc'
      - 'AI_Service/app/chatbot/data/*.dvc'
      - 'AI_Service/app/**.py'
      - 'AI_Service/tests/**.py'
  schedule:
    - cron: '0 14 * * *'

permissions:
  contents: write

jobs:
  validate-and-version:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Verify DVC repository structure
        working-directory: AI_Service
        run: |
          ls -la
          ls -la .dvc || echo "DVC directory (.dvc) not found!"
          cat .dvc/config || echo "DVC config file (.dvc/config) not found!"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install great_expectations==0.18.21 pandas dvc[gdrive]==3.55.2

      - name: Configure Google Drive service account
        env:
          GDRIVE_SA_CREDENTIALS: ${{ secrets.GDRIVE_SA_CREDENTIALS }}
        run: |
          echo "$GDRIVE_SA_CREDENTIALS" > AI_Service/gdrive-sa.json
          python -c "import json; json.load(open('AI_Service/gdrive-sa.json'))" || { echo "Invalid JSON in gdrive-sa.json"; exit 1; }
          cd AI_Service
          dvc remote modify myremote gdrive_use_service_account true
          dvc remote modify myremote gdrive_service_account_json_file_path gdrive-sa.json

      - name: Pull DVC files
        run: |
          cd AI_Service
          dvc pull
          ls -la app/models/
          ls -la app/data/ app/chatbot/data/

      - name: Ensure model and data files exist
        working-directory: AI_Service
        run: |
          for file in app/models/best_model.pkl app/models/scaler.pkl app/models/encoder.pkl app/models/tfidf.pkl app/models/all_tags.pkl app/models/features.pkl app/chatbot/data/metadata.pkl app/chatbot/data/faiss_index.bin; do
            if [ ! -f "$file" ]; then
              echo "Error: $file not found"
              exit 1
            fi
          done

      - name: Run Great Expectations checkpoint for intents
        working-directory: AI_Service
        run: |
          python manage-great_expectations/create_intents_checkpoint.py > intents_output.log 2>&1
          cat intents_output.log

      - name: Check intents validation result
        working-directory: AI_Service
        run: |
          if grep -q "Success: False" intents_output.log || grep -q "Erreur" intents_output.log; then
            echo "Intents validation failed! Check the output above for details."
            exit 1
          fi
        if: always()

      - name: Run Great Expectations checkpoint for tasks
        working-directory: AI_Service
        run: |
          python manage-great_expectations/create_checkpoint.py > tasks_output.log 2>&1
          cat tasks_output.log

      - name: Check tasks validation result
        working-directory: AI_Service
        run: |
          if grep -q "Success: False" tasks_output.log || grep -q "Erreur" tasks_output.log; then
            echo "Tasks validation failed! Check the output above for details."
            exit 1
          fi
        if: always()

      - name: Version data with DVC
        working-directory: AI_Service
        run: |
          dvc add app/data/intents_complete.json || echo "No changes in intents_complete.json"
          dvc add app/data/tasks_dataset.csv || echo "No changes in tasks_dataset.csv"
          git add app/data/*.dvc app/models/*.dvc
          git commit -m "Versionner les fichiers de donnÃ©es avec DVC" || echo "Aucun changement Ã  versionner."
          dvc push

      - name: Push Git changes
        run: |
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Send Slack notification
        uses: slackapi/slack-github-action@v1.26.0
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        with:
          channel-id: 'C08V19BHQVB'
          slack-message: |
            ${{ job.status == 'success' && 'âœ… Les donnÃ©es ont passÃ© la validation et ont Ã©tÃ© versionnÃ©es avec succÃ¨s !' || 'ðŸš¨ Alerte : Ã‰chec de la validation ou du versioning. VÃ©rifiez les logs : https://github.com/fatimaflous/gestion_projet/actions/runs/${{ github.run_id }}' }}
        if: always()

  run-tests:
    runs-on: ubuntu-latest
    needs: validate-and-version
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r AI_Service/requirements.txt
          pip install pytest==8.3.3 pytest-asyncio==0.24.0 pytest-cov==5.0.0

      - name: Configure Google Drive service account
        env:
          GDRIVE_SA_CREDENTIALS: ${{ secrets.GDRIVE_SA_CREDENTIALS }}
        run: |
          echo "$GDRIVE_SA_CREDENTIALS" > AI_Service/gdrive-sa.json
          python -c "import json; json.load(open('AI_Service/gdrive-sa.json'))" || { echo "Invalid JSON in gdrive-sa.json"; exit 1; }
          cd AI_Service
          dvc remote modify myremote gdrive_use_service_account true
          dvc remote modify myremote gdrive_service_account_json_file_path gdrive-sa.json

      - name: Pull DVC files
        run: |
          cd AI_Service
          dvc pull
          ls -la app/models/
          ls -la app/chatbot/data/

      - name: Ensure model files exist
        working-directory: AI_Service
        run: |
          for file in app/models/best_model.pkl app/models/scaler.pkl app/models/encoder.pkl app/models/tfidf.pkl app/models/all_tags.pkl app/models/features.pkl; do
            if [ ! -f "$file" ]; then
              echo "Error: $file not found"
              exit 1
            fi
          done

      - name: Create .env file
        run: |
          cat << EOF > AI_Service/.env
          MODEL_PATH=app/models/best_model.pkl
          SCALER_PATH=app/models/scaler.pkl
          ENCODER_PATH=app/models/encoder.pkl
          TFIDF_PATH=app/models/tfidf.pkl
          TAGS_PATH=app/models/all_tags.pkl
          FEATURES_PATH=app/models/features.pkl
          LOG_LEVEL=INFO
          INTENTS_PATH=app/chatbot/data/intents_complete.json
          FAISS_INDEX_PATH=app/chatbot/data/faiss_index.bin
          METADATA_PATH=app/chatbot/data/metadata.pkl
          CACHE_PATH=app/chatbot/data/cache.json
          PROJECT_API_URL=http://localhost:8085/api/chatbot/projects
          TASK_API_URL=http://localhost:8086/api/chatbot/tasks
          EOF

      - name: Run pytest
        working-directory: AI_Service
        run: |
          pytest tests/ --asyncio-mode=auto --cov=app --cov-report=xml:coverage.xml --cov-report=html:cov_html --cov-config=.coveragerc --cov-branch -v || echo "Pytest failed, check logs above"

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: AI_Service/coverage.xml
        if: always()

      - name: Upload coverage HTML report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-html
          path: AI_Service/cov_html
        if: always()
        
      - name: Install XML tools
        run: sudo apt-get install -y libxml2-utils

      - name: Extract coverage data
        id: coverage
        run: |
            LINE_COVERAGE=$(xmllint --xpath "string(//coverage/@line-rate)" AI_Service/coverage.xml)
            BRANCH_COVERAGE=$(xmllint --xpath "string(//coverage/@branch-rate)" AI_Service/coverage.xml)
    
            # Conversion en pourcentage
            LINE_PERCENT=$(awk "BEGIN {printf \"%.2f\", $LINE_COVERAGE * 100}")
            BRANCH_PERCENT=$(awk "BEGIN {printf \"%.2f\", $BRANCH_COVERAGE * 100}")

            echo "line=${LINE_PERCENT}" >> $GITHUB_OUTPUT
            echo "branch=${BRANCH_PERCENT}" >> $GITHUB_OUTPUT

      - name: Send Slack notification
        uses: slackapi/slack-github-action@v1.26.0
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        with:
          channel-id: 'C08V19BHQVB'
          slack-message: |
            ${{ job.status == 'success' && format('âœ… Tous les tests pytest ont rÃ©ussi ! Couverture des lignes : {0}%, branches : {1}%.', steps.coverage.outputs.line, steps.coverage.outputs.branch) || format('ðŸš¨ Alerte : Ã‰chec des tests pytest. VÃ©rifiez les logs : https://github.com/fatimaflous/gestion_projet/actions/runs/{0}', github.run_id) }}

        if: always()

  sonar-analysis:
    runs-on: ubuntu-latest
    needs: run-tests
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install DVC
        run: |
          python -m pip install --upgrade pip
          pip install dvc[gdrive]==3.55.2

      - name: Configure Google Drive service account
        env:
          GDRIVE_SA_CREDENTIALS: ${{ secrets.GDRIVE_SA_CREDENTIALS }}
        run: |
          echo "$GDRIVE_SA_CREDENTIALS" > AI_Service/gdrive-sa.json
          python -c "import json; json.load(open('AI_Service/gdrive-sa.json'))" || { echo "Invalid JSON in gdrive-sa.json"; exit 1; }
          cd AI_Service
          dvc remote modify myremote gdrive_use_service_account true
          dvc remote modify myremote gdrive_service_account_json_file_path gdrive-sa.json

      - name: Pull DVC files
        run: |
          cd AI_Service
          dvc pull
          ls -la app/ app/data/ app/models/ app/chatbot/data/ || echo "DVC files not found"

      - name: Download coverage report
        uses: actions/download-artifact@v4
        with:
          name: coverage-report
          path: AI_Service/

      - name: SonarQube Scan
        uses: SonarSource/sonarcloud-github-action@v3.0.0
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        with:
          args: >
            -Dsonar.organization=fatimaaflous
            -Dsonar.projectKey=fatimaaflous_gestion_projet
            -Dsonar.python.version=3.12
            -Dsonar.projectBaseDir=AI_Service
            -Dsonar.sources=app
            -Dsonar.tests=tests
            -Dsonar.python.coverage.reportPaths=coverage.xml
            -Dsonar.exclusions=**/tests/**,**/manage-great_expectations/**,**/__init__.py
            -Dsonar.coverage.exclusions=**/__init__.py
            -Dsonar.scm.provider=git
            -Dsonar.scm.revision=main
            -Dsonar.branch.name=main
            -Dsonar.python.coveragePlugin=cobertura


      - name: Send Slack notification
        uses: slackapi/slack-github-action@v1.26.0
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        with:
          channel-id: 'C08V19BHQVB'
          slack-message: |
            ${{ job.status == 'success' && 'âœ… Analyse SonarCloud terminÃ©e ! RÃ©sultats : https://sonarcloud.io/project/overview?id=fatimaaflous_gestion_projet' || format('ðŸš¨ Ã‰chec de lâ€™analyse SonarCloud. VÃ©rifiez les logs : https://github.com/fatimaflous/gestion_projet/actions/runs/{0}', github.run_id) }}
        if: always()


  train-model:
    runs-on: ubuntu-latest
    needs: sonar-analysis
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r AI_Service/requirements.txt
          pip install mlflow==2.17.0 dvc[gdrive]==3.55.2

      - name: Configure Google Drive service account
        env:
          GDRIVE_SA_CREDENTIALS: ${{ secrets.GDRIVE_SA_CREDENTIALS }}
        run: |
          echo "$GDRIVE_SA_CREDENTIALS" > AI_Service/gdrive-sa.json
          python -c "import json; json.load(open('AI_Service/gdrive-sa.json'))" || { echo "Invalid JSON in gdrive-sa.json"; exit 1; }
          cd AI_Service
          dvc remote modify myremote gdrive_use_service_account true
          dvc remote modify myremote gdrive_service_account_json_file_path gdrive-sa.json

      - name: Pull DVC files
        run: |
          cd AI_Service
          dvc pull
          ls -la app/models/ app/data/ app/chatbot/data/

      - name: Create .env file
        run: |
          cat << EOF > AI_Service/.env
          DATA_PATH=app/data/tasks_dataset.csv
          MODEL_PATH=app/models/best_model.pkl
          SCALER_PATH=app/models/scaler.pkl
          ENCODER_PATH=app/models/encoder.pkl
          TFIDF_PATH=app/models/tfidf.pkl
          TAGS_PATH=app/models/all_tags.pkl
          FEATURES_PATH=app/models/features.pkl
          INTENTS_PATH=app/data/intents_complete.json
          FAISS_INDEX_PATH=app/chatbot/data/faiss_index.bin
          METADATA_PATH=app/chatbot/data/metadata.pkl
          CACHE_PATH=app/chatbot/data/cache.json
          SIMILARITY_THRESHOLD=0.8
          LOG_LEVEL=INFO
          PROJECT_API_URL=http://localhost:8085/api/chatbot/projects
          TASK_API_URL=http://localhost:8086/api/chatbot/tasks
          EOF

      - name: Check modified files
        id: check_files
        run: |
          MODIFIED_FILES=$(git diff --name-only HEAD^ HEAD || echo "")
          if [[ "$MODIFIED_FILES" =~ "AI_Service/app/data/tasks_dataset.csv.dvc" ]]; then
            echo "predictor=true" >> $GITHUB_OUTPUT
          else
            echo "predictor=false" >> $GITHUB_OUTPUT
          fi
          if [[ "$MODIFIED_FILES" =~ "AI_Service/app/data/intents_complete.json.dvc" ]]; then
            echo "chatbot=true" >> $GITHUB_OUTPUT
          else
            echo "chatbot=false" >> $GITHUB_OUTPUT
          fi
          echo "Modified files: $MODIFIED_FILES"

      - name: Train predictor model
        if: steps.check_files.outputs.predictor == 'true'
        working-directory: AI_Service
        run: |
          python app/training/train_predictor.py || { echo "Predictor training failed"; exit 1; }

      - name: Train chatbot model
        if: steps.check_files.outputs.chatbot == 'true'
        working-directory: AI_Service
        run: |
          python app/training/train_chatbot.py || { echo "Chatbot training failed"; exit 1; }

      - name: Version predictor files with DVC
        if: steps.check_files.outputs.predictor == 'true'
        working-directory: AI_Service
        run: |
          git config --global user.email "github-actions@users.noreply.github.com"
          git config --global user.name "GitHub Actions"
          dvc add app/models/best_model.pkl app/models/scaler.pkl app/models/encoder.pkl app/models/tfidf.pkl app/models/all_tags.pkl app/models/features.pkl
          git add app/models/*.dvc
          git commit -m "Versionner les fichiers du modÃ¨le de prÃ©diction avec DVC" || echo "Aucun changement Ã  versionner."
          dvc push

      - name: Version chatbot files with DVC
        if: steps.check_files.outputs.chatbot == 'true'
        working-directory: AI_Service
        run: |
          git config --global user.email "github-actions@users.noreply.github.com"
          git config --global user.name "GitHub Actions"
          dvc add app/chatbot/data/faiss_index.bin app/chatbot/data/metadata.pkl
          git add app/chatbot/data/*.dvc
          git commit -m "Versionner les fichiers du chatbot avec DVC" || echo "Aucun changement Ã  versionner."
          dvc push

      - name: Send Slack notification
        uses: slackapi/slack-github-action@v1.26.0
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        with:
          channel-id: 'C08V19BHQVB'
          slack-message: |
            ${{ job.status == 'success' && 'âœ… EntraÃ®nement rÃ©ussi ! Fichiers versionnÃ©s sur Google Drive.' || 'ðŸš¨ Alerte : Ã‰chec de lâ€™entraÃ®nement. VÃ©rifiez les logs : https://github.com/fatimaflous/gestion_projet/actions/runs/${{ github.run_id }}' }}
        if: always()

        
  build-and-push-docker:
    runs-on: ubuntu-latest
    needs: train-model
    permissions:
      contents: read
      packages: write
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Debug directory structure
      run: |
        pwd
        ls -la
        find . -maxdepth 3
      continue-on-error: true

    - name: Clean up disk space
      run: |
        df -h
        sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /tmp/*
        docker system prune -af
        df -h
      continue-on-error: true

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'

    - name: Install DVC
      run: |
        python -m pip install --no-cache-dir --upgrade pip
        pip install --no-cache-dir dvc[gdrive]==3.55.2

    - name: Configure Google Drive service account
      env:
        GDRIVE_SA_CREDENTIALS: ${{ secrets.GDRIVE_SA_CREDENTIALS }}
      run: |
        echo "$GDRIVE_SA_CREDENTIALS" > AI_Service/gdrive-sa.json
        python -c "import json; json.load(open('AI_Service/gdrive-sa.json'))" || { echo "Invalid JSON in gdrive-sa.json"; exit 1; }
        cd AI_Service
        dvc remote modify myremote gdrive_use_service_account true
        dvc remote modify myremote gdrive_service_account_json_file_path gdrive-sa.json
        rm -f AI_Service/gdrive-sa.json

    - name: Pull DVC files
      run: |
        cd AI_Service
        dvc pull app/models/best_model.pkl app/models/scaler.pkl app/models/encoder.pkl app/models/tfidf.pkl app/models/all_tags.pkl app/models/features.pkl app/data/intents_complete.json app/data/tasks_dataset.csv app/chatbot/data/faiss_index.bin app/chatbot/data/metadata.pkl
        ls -la app/models/ app/data/ app/chatbot/data/
        du -sh app/models app/data app/chatbot/data

    - name: Clean up after DVC pull
      run: |
        df -h
        sudo rm -rf /tmp/*
        docker system prune -af
        df -h
      continue-on-error: true

    - name: Create .env file
      run: |
        cat << EOF > AI_Service/.env
        MODEL_PATH=app/models/best_model.pkl
        SCALER_PATH=app/models/scaler.pkl
        ENCODER_PATH=app/models/encoder.pkl
        TFIDF_PATH=app/models/tfidf.pkl
        TAGS_PATH=app/models/all_tags.pkl
        FEATURES_PATH=app/models/features.pkl
        DATA_PATH=app/data/tasks_dataset.csv
        INTENTS_PATH=app/data/intents_complete.json
        FAISS_INDEX_PATH=app/chatbot/data/faiss_index.bin
        METADATA_PATH=app/chatbot/data/metadata.pkl
        CACHE_PATH=app/chatbot/data/cache.json
        SIMILARITY_THRESHOLD=0.8
        LOG_LEVEL=INFO
        PROJECT_API_URL=http://localhost:8085/api/chatbot/projects
        TASK_API_URL=http://localhost:8086/api/chatbot/tasks
        EOF
        cat AI_Service/.env

    - name: Verify requirements.txt
      run: |
        ls -la AI_Service/requirements.txt
        cat AI_Service/requirements.txt

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Clean Docker Buildx
      run: |
        docker buildx rm --all-inactive || true
        docker buildx prune -f
      continue-on-error: true

    - name: Log in to GitHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Build and push Docker image
      run: |
        docker build -t ghcr.io/${{ github.repository }}/ai-service:latest -f AI_Service/Dockerfile --no-cache AI_Service
        docker push ghcr.io/${{ github.repository }}/ai-service:latest

    - name: Inspect Docker image size
      run: |
        docker images ghcr.io/${{ github.repository }}/ai-service:latest
        docker image inspect ghcr.io/${{ github.repository }}/ai-service:latest | jq '. [0].Size' | awk '{print $1/1024/1024 "MB"}'
      continue-on-error: true

    - name: Clean up after Docker build
      run: |
        df -h
        sudo rm -rf /tmp/*
        docker system prune -f
        df -h
      continue-on-error: true

    - name: Send Slack notification
      uses: slackapi/slack-github-action@v1.26.0
      env:
        SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
      with:
        channel-id: 'C08V19BHQVB'
        slack-message: |
          ${{ job.status == 'success' && format('âœ… Image Docker construite et poussÃ©e vers GHCR : ghcr.io/{0}/ai-service:latest', github.repository) || format('ðŸš¨ Ã‰chec de la construction/push de lâ€™image Docker. VÃ©rifiez les logs : https://github.com/{0}/actions/runs/{1}', github.repository, github.run_id) }}
      if: always()

      
  deploy-monitoring:
    runs-on: ubuntu-latest
    needs: build-and-push-docker
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Create Docker network
        run: |
          docker network create monitoring || true

      - name: Create monitoring directory
        run: |
          mkdir -p AI_Service/monitoring/grafana/provisioning/datasources

      - name: Create Prometheus configuration
        run: |
          cat << EOF > AI_Service/monitoring/prometheus.yml
          global:
            scrape_interval: 15s
            evaluation_interval: 15s
          alerting:
            alertmanagers:
              - static_configs:
                  - targets: []
          rule_files:
            - "/etc/prometheus/alerts.yml"
          scrape_configs:
            - job_name: 'pushgateway'
              static_configs:
                - targets: ['pushgateway:9091']
            - job_name: 'prometheus'
              static_configs:
                - targets: ['localhost:9090']
            - job_name: 'ai_service'
              static_configs:
                - targets: ['ai-service:8000']  # Scrape lâ€™endpoint /metrics de AI_Service
          EOF

      - name: Create Prometheus alerting rules
        run: |
          cat << EOF > AI_Service/monitoring/alerts.yml
          groups:
          - name: example
            rules:
            - alert: HighErrorRate
              expr: job:request_error_rate:sum{job="ai_service"} > 0.05
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: "Taux d'erreur Ã©levÃ© dÃ©tectÃ©"
                description: "Le taux d'erreur pour {{ \$labels.job }} est de {{ \$value }}%, au-dessus du seuil de 5%."
          EOF

      - name: Create Grafana provisioning for Prometheus datasource
        run: |
          cat << EOF > AI_Service/monitoring/grafana/provisioning/datasources/datasource.yml
          apiVersion: 1
          datasources:
            - name: Prometheus
              type: prometheus
              url: http://prometheus:9090
              access: proxy
              isDefault: true
          EOF

      - name: Run AI_Service container
        run: |
          docker run -d \
            --name ai-service \
            --network monitoring \
            -p 8000:8000 \
            -v $(pwd)/AI_Service/.env:/app/.env \
            ghcr.io/fatimaflous/gestion_projet/ai-service:latest

      - name: Run Prometheus container
        run: |
          docker run -d \
            --name prometheus \
            --network monitoring \
            -p 9090:9090 \
            -v $(pwd)/AI_Service/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml \
            -v $(pwd)/AI_Service/monitoring/alerts.yml:/etc/prometheus/alerts.yml \
            prom/prometheus:v2.54.1

      - name: Run Pushgateway container
        run: |
          docker run -d \
            --name pushgateway \
            --network monitoring \
            -p 9091:9091 \
            prom/pushgateway:v1.9.0

      - name: Run Grafana container
        run: |
          docker run -d \
            --name grafana \
            --network monitoring \
            -p 3000:3000 \
            -e GF_SECURITY_ADMIN_USER=admin \
            -e GF_SECURITY_ADMIN_PASSWORD=${{ secrets.GRAFANA_ADMIN_PASSWORD }} \
            -v $(pwd)/AI_Service/monitoring/grafana/provisioning:/etc/grafana/provisioning \
            grafana/grafana:11.2.0

      - name: Wait for services to start
        run: |
          sleep 15
          docker ps -a

      - name: Verify AI_Service is running
        run: |
          curl -s http://localhost:8000/health | jq . || echo "AI_Service health check failed"
          if [ $? -ne 0 ]; then
            echo "AI_Service n'est pas en cours d'exÃ©cution"
            exit 1
          fi

      - name: Verify Prometheus is running
        run: |
          curl -s http://localhost:9090/api/v1/status/buildinfo | jq .
          if [ $? -ne 0 ]; then
            echo "Prometheus n'est pas en cours d'exÃ©cution"
            exit 1
          fi

      - name: Verify Pushgateway is running
        run: |
          curl -s http://localhost:9091/-/healthy
          if [ $? -ne 0 ]; then
            echo "Pushgateway n'est pas en cours d'exÃ©cution"
            exit 1
          fi

      - name: Verify Grafana is running
        run: |
          curl -s http://localhost:3000/api/health | jq .
          if [ $? -ne 0 ]; then
            echo "Grafana n'est pas en cours d'exÃ©cution"
            exit 1
          fi

      - name: Push sample metrics to Pushgateway
        run: |
          echo 'ai_service_requests_total{job="ai_service",endpoint="/predict"} 100' | curl --data-binary @- http://localhost:9091/metrics/job/ai_service
          echo 'ai_service_request_error_rate{job="ai_service",endpoint="/predict"} 0.02' | curl --data-binary @- http://localhost:9091/metrics/job/ai_service
          curl -s http://localhost:9091/api/v1/metrics | grep ai_service

      - name: Configure Grafana dashboard
        run: |
          curl -X POST \
            -H "Content-Type: application/json" \
            -H "Authorization: Basic $(echo -n admin:${{ secrets.GRAFANA_ADMIN_PASSWORD }} | base64)" \
            -d '{
              "dashboard": {
                "id": null,
                "title": "MÃ©triques AI Service",
                "tags": ["ai_service"],
                "timezone": "browser",
                "schemaVersion": 36,
                "version": 0,
                "panels": [
                  {
                    "id": 1,
                    "title": "RequÃªtes Totales",
                    "type": "timeseries",
                    "datasource": "Prometheus",
                    "targets": [
                      {
                        "expr": "ai_service_requests_total{job=\"ai_service\"}",
                        "legendFormat": "{{endpoint}}",
                        "format": "time_series"
                      }
                    ],
                    "gridPos": { "x": 0, "y": 0, "w": 12, "h": 8 }
                  },
                  {
                    "id": 2,
                    "title": "Taux dâ€™Erreur",
                    "type": "timeseries",
                    "datasource": "Prometheus",
                    "targets": [
                      {
                        "expr": "ai_service_request_error_rate{job=\"ai_service\"}",
                        "legendFormat": "{{endpoint}}",
                        "format": "time_series"
                      }
                    ],
                    "gridPos": { "x": 12, "y": 0, "w": 12, "h": 8 }
                  }
                ]
              },
              "overwrite": true,
              "folderId": 0
            }' \
            http://localhost:3000/api/dashboards/db

      - name: Send Slack notification for monitoring
        uses: slackapi/slack-github-action@v1.26.0
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        with:
          channel-id: 'C08V19BHQVB'
          text: |
            ${{ job.status == 'success' && 'âœ… Stack de monitoring (Prometheus, Pushgateway, Grafana) dÃ©ployÃ©e avec succÃ¨s dans GitHub Actions !' || format('ðŸš¨ Ã‰chec du dÃ©ploiement de la stack de monitoring. VÃ©rifiez les logs : https://github.com/{0}/actions/runs/{1}', github.repository, github.run_id) }}
        if: always()

      - name: Send Slack alert for high error rate
        if: always()
        run: |
          ERROR_RATE=$(curl -s 'http://localhost:9090/api/v1/query?query=ai_service_request_error_rate{job="ai_service"}' | jq -r '.data.result[0].value[1]' || echo "0")
          if (( $(echo "$ERROR_RATE > 0.05" | bc -l) )); then
            curl -X POST \
              -H 'Content-type: application/json' \
              -H "Authorization: Bearer ${{ secrets.SLACK_BOT_TOKEN }}" \
              -d "{\"channel\":\"C08V19BHQVB\",\"text\":\"ðŸš¨ Alerte : Taux d'erreur Ã©levÃ© dÃ©tectÃ© : ${ERROR_RATE}% (seuil : 5%)\"}" \
              https://slack.com/api/chat.postMessage
          fi
